{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 将NII文件转换为PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "# 转换成图像\n",
    "import imageio\n",
    "imgfile=\"temp/0017691773FILT.nii\"\n",
    "file_path=\"/mnt/hdd1/zhulu/hospital/first_stage_nii/zhao_yong_xing_20180823_005_B01-HX-cognitive_disorde_Ax_SWAN_new.nii\"\n",
    "img = nib.load(file_path)\n",
    "img_fdata = img.get_fdata()\n",
    "\n",
    "    \n",
    "(x, y, z) = img.shape\n",
    "# z是图像的序列\n",
    "output_dir = '/mnt/hdd1/zhulu/hospital/first_stage_nii/swan'\n",
    "for i in range(z):\n",
    "    # 选择哪个方向的切片都可以\n",
    "    silce = img_fdata[:, :, i]\n",
    "    # 保存图像\n",
    "    # 归一化切片数据到0-255范围，并转换为uint8类型\n",
    "    slice_data = ((silce - np.min(silce)) / (np.max(silce) - np.min(silce)) * 255).astype(np.uint8)\n",
    "\n",
    "    # 将当前切片保存为 PNG\n",
    "    output_file = os.path.join(output_dir, '{}.png'.format(i+1))\n",
    "    imageio.imwrite(output_file, slice_data)\n",
    "                            \n",
    "x=1+3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 将病人数据txt按照高/低分辨率进行归类，合成总的数据集，并删除掉其中非出血点标签，清除空文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def clear_folder(folder_path):\n",
    "    # 检查文件夹是否存在\n",
    "    if os.path.exists(folder_path):\n",
    "        # 遍历文件夹中的所有文件和子文件夹\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                # 删除文件或文件夹\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.remove(file_path)  # 删除文件或符号链接\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)  # 删除文件夹及其内容\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "    else:\n",
    "        print(f\"Folder {folder_path} does not exist.\")\n",
    "\n",
    "# # 清理高分辨率和低分辨率文件夹\n",
    "# clear_folder(high_resolution_folder)\n",
    "# clear_folder(low_resolution_folder)\n",
    "\n",
    "# print(\"Folders have been cleared.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil\n",
    "#此处训练集和验证集都要进行删除\n",
    "#训练集如果不删除其他标签数据报错明显，但是测试集不删除报错提示不明显\n",
    "\"\"\" 注意是train和val都要删除 \"\"\"\n",
    "# train_txt=\"/mnt/hdd1/zhulu/hospital/labels/train\"  \n",
    "# txt_files=os.listdir(train_txt)\n",
    "\n",
    "def adjust_yolo_file(file_dir):\n",
    "    txt_files=os.listdir(file_dir)\n",
    "    for file in txt_files:\n",
    "        file_path=os.path.join(file_dir,file)\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # 选出符合出血点标签的行\n",
    "        updated_lines = [line for line in lines if line.strip().split()[0] == \"0\"]\n",
    "        \n",
    "        if len(updated_lines)==0: #如果文件没有出血点的标注，则直接删除文件\n",
    "            os.remove(file_path)\n",
    "        else:\n",
    "            # 将更新后的内容写回文件\n",
    "            with open(file_path, 'w') as f:\n",
    "                f.writelines(updated_lines)\n",
    "                \n",
    "low_resolution=[\"Patient-0000406857\",\"Patient-0000589446\",'Patient-0000745885','Patient-0003537968'\n",
    "                ,'Patient-0010134951','Patient-0018227242','Patient-0018463963']\n",
    "all_second_patient_path=\"/mnt/hdd1/zhulu/blood_stage2/blood_anno/PNG\"\n",
    "all_second_patients=os.listdir(all_second_patient_path)\n",
    "\n",
    "high_resolution_folder=\"/mnt/hdd1/zhulu/hospital/high_resolution\"\n",
    "low_resolution_folder=\"/mnt/hdd1/zhulu/hospital/low_resolution\"\n",
    "\n",
    "clear_folder(high_resolution_folder)\n",
    "clear_folder(low_resolution_folder)\n",
    "\n",
    "#移动文件，先移动label\n",
    "for patient in all_second_patients:\n",
    "    patient_lable_path=os.path.join(all_second_patient_path,patient,\"label\")\n",
    "    if patient in low_resolution:\n",
    "        for item in os.listdir(patient_lable_path):\n",
    "            source_item = os.path.join(patient_lable_path, item)\n",
    "            # 因为源文件夹下的文件命名没有病人编号，因此需要重命名过去\n",
    "            target_item = os.path.join(low_resolution_folder, patient+\"_\"+item)\n",
    "            # target_item = os.path.join(low_resolution_folder, item)\n",
    "            if os.path.isfile(source_item):\n",
    "                shutil.copy2(source_item, target_item)\n",
    "    else:\n",
    "        for item in os.listdir(patient_lable_path):\n",
    "            source_item = os.path.join(patient_lable_path, item)\n",
    "            target_item = os.path.join(high_resolution_folder,patient+\"_\"+item)\n",
    "            if os.path.isfile(source_item):\n",
    "                shutil.copy2(source_item, target_item)\n",
    "\n",
    "#删除非出血点标签，删除空白文件txt\n",
    "adjust_yolo_file(high_resolution_folder)\n",
    "adjust_yolo_file(low_resolution_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按照病人编号进行排序，计算出血点个数，按照8：2进行训练集和测试集的划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient-0018471528_img-00005-00059.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 以下复制移动文件是通过手动的方式,xftp文件可以按照文件名进行排序 \"\"\"\n",
    "import os\n",
    "import re\n",
    "\n",
    "def change_seq(file_dir):\n",
    "    train_labels=os.listdir(file_dir)\n",
    "    for train_label in train_labels:\n",
    "        patien_name,suffix=train_label.split(\"_\")\n",
    "        img,seq,layer=suffix.split(\"-\")\n",
    "        new_file_name=patien_name+\"_img-00005-\"+layer\n",
    "        old_file=os.path.join(file_dir,train_label)\n",
    "        new_file=os.path.join(file_dir,new_file_name)\n",
    "        os.rename(old_file, new_file)\n",
    "\n",
    "def extract_patient_id(file_name):\n",
    "    match = re.search(r'Patient-(\\d+)', file_name)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "high_folder=\"/mnt/hdd1/zhulu/hospital/high_resolution\"\n",
    "\n",
    "change_seq(high_folder)  # 先修改每个文件的序列号，swi为00005\n",
    "high_files=os.listdir(high_folder)\n",
    "# 按照病人编号进行排序，确保同一个病人只在训练集或者测试集\n",
    "sorted_file_list = sorted(high_files, key=extract_patient_id)  \n",
    "all_CMB_annos=0\n",
    "for file in sorted_file_list:\n",
    "    with open(os.path.join(high_folder,file), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    all_CMB_annos+=len(lines)  \n",
    "    #Patient-0018471528_img-00005-00059.txt 高分辨率下，8：2的分界点\n",
    "    #后面是服务器上手动复制粘贴过去的（服务器上本身已经按照病患编号进行排序了）\n",
    "    if  all_CMB_annos==540:  #540是总的all_CMB_annos，按照8：2的划分中间\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变label的编码，swi为00005,phase为00500\n",
    "import os\n",
    "train_label_dir=\"/mnt/hdd1/zhulu/hospital/labels/high_resolution/val\"\n",
    "train_labels=os.listdir(train_label_dir)\n",
    "\n",
    "def change_seq(file_dir):\n",
    "    train_labels=os.listdir(file_dir)\n",
    "    for train_label in train_labels:\n",
    "        patien_name,suffix=train_label.split(\"_\")\n",
    "        img,seq,layer=suffix.split(\"-\")\n",
    "        new_file_name=patien_name+\"_img-00005-\"+layer\n",
    "        old_file=os.path.join(file_dir,train_label)\n",
    "        new_file=os.path.join(file_dir,new_file_name)\n",
    "        os.rename(old_file, new_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 根据label txt文件名，将对应的图像也划分到images下面的训练和测试文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\"\"\" 注意train和val都需要换 \"\"\"\n",
    "split=\"val\"\n",
    "train_lable_files_dir=f\"/mnt/hdd1/zhulu/hospital/labels/high_resolution/{split}\"\n",
    "second_patients_dir=\"/mnt/hdd1/zhulu/blood_stage2/blood_anno/PNG\"\n",
    "target_dir=f\"/mnt/hdd1/zhulu/hospital/images/high_resolution/{split}\"\n",
    "patients=os.listdir(second_patients_dir)\n",
    "train_label_files=os.listdir(train_lable_files_dir)\n",
    "for train_label_file in train_label_files:\n",
    "    patient_id=train_label_file.split(\"_\")[0]\n",
    "    img_id=train_label_file.split(\"_\")[1].split(\".\")[0]+\".png\"\n",
    "    patient_img_dir=os.path.join(second_patients_dir,patient_id,\"Series-Ax SWAN new\")\n",
    "    img_path=os.path.join(patient_img_dir,img_id)\n",
    "    # 将原本文件patient_id_img_id.png整个名称也要复制过去\n",
    "    target_path=os.path.join(target_dir,train_label_file.split(\".\")[0]+\".png\") \n",
    "    shutil.copy2(img_path, target_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第二阶段数据进行8:2划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from math import ceil\n",
    "\n",
    "# 定义源文件夹和目标文件夹\n",
    "resolution=\"high\"\n",
    "is_CMB=\"CMB\"\n",
    "source_dir = f'/mnt/hdd1/zhulu/hospital/second_stage/train_model/{resolution}/all/{is_CMB}'\n",
    "train_dir = f'/mnt/hdd1/zhulu/hospital/second_stage/train_model/{resolution}/train/{is_CMB}'\n",
    "test_dir = f'/mnt/hdd1/zhulu/hospital/second_stage/train_model/{resolution}/test/{is_CMB}'\n",
    "\n",
    "# 创建目标文件夹，如果它们不存在\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# 获取源文件夹中的所有文件\n",
    "all_files = os.listdir(source_dir)\n",
    "\n",
    "# 设置随机种子以确保每次运行结果一致\n",
    "random.seed(42)\n",
    "\n",
    "# 打乱文件列表\n",
    "random.shuffle(all_files)\n",
    "\n",
    "# 计算80%和20%的切分点\n",
    "split_point = ceil(len(all_files) * 0.8)\n",
    "\n",
    "# 切分文件列表\n",
    "train_files = all_files[:split_point]\n",
    "test_files = all_files[split_point:]\n",
    "\n",
    "# 将文件复制到训练和测试文件夹\n",
    "for file in train_files:\n",
    "    shutil.copy(os.path.join(source_dir, file), train_dir)\n",
    "\n",
    "for file in test_files:\n",
    "    shutil.copy(os.path.join(source_dir, file), test_dir)\n",
    "\n",
    "print(f\"已将{len(train_files)}个文件复制到{train_dir}\")\n",
    "print(f\"已将{len(test_files)}个文件复制到{test_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将.dcm数据转换为nii数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def dcm_to_nii(dcm_folder, nii_filename):\n",
    "    \"\"\"\n",
    "    将一个包含多个DICOM文件的文件夹转换为NIfTI格式文件。\n",
    "    \n",
    "    参数：\n",
    "    dcm_folder : str : DICOM文件所在的文件夹路径\n",
    "    nii_filename : str : 输出NIfTI文件的路径\n",
    "    \"\"\"\n",
    "    # 获取所有的DICOM文件\n",
    "    dcm_files = [os.path.join(dcm_folder, f) for f in os.listdir(dcm_folder) if f.endswith('.dcm')]\n",
    "    \n",
    "    # 按照DICOM文件的InstanceNumber或者SliceLocation排序（确保切片顺序正确）\n",
    "    dcm_files.sort(key=lambda x: int(pydicom.dcmread(x).InstanceNumber))\n",
    "    \n",
    "    # 读取所有DICOM切片\n",
    "    slices = []\n",
    "    for dcm_file in dcm_files:\n",
    "        dicom_data = pydicom.dcmread(dcm_file)\n",
    "        slices.append(dicom_data.pixel_array)\n",
    "    \n",
    "    # 将切片数据转换为3D NumPy数组\n",
    "    image_3d = np.stack(slices, axis=-1)\n",
    "    \n",
    "    # 获取DICOM的相关元数据（如空间维度、像素间距等）\n",
    "    first_dcm = pydicom.dcmread(dcm_files[0])\n",
    "    affine = np.diag([first_dcm.PixelSpacing[0], first_dcm.PixelSpacing[1], first_dcm.SliceThickness, 1])  # 假设Affine为标准\n",
    "\n",
    "    # 创建NIfTI图像\n",
    "    nii_img = nib.Nifti1Image(image_3d, affine)\n",
    "    \n",
    "    # 保存NIfTI文件\n",
    "    nib.save(nii_img, nii_filename)\n",
    "    print(f\"成功将DICOM转换为NIfTI格式：{nii_filename}\")\n",
    "\n",
    "# 使用示例\n",
    "dcm_folder = '/mnt/hdd1/zhulu/005_AxSWANnew'  # 你的DICOM文件夹路径\n",
    "nii_filename = '/mnt/hdd1/zhulu/output_file.nii'  # 输出NIfTI文件路径\n",
    "dcm_to_nii(dcm_folder, nii_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_folders=\"/mnt/hdd1/zhulu/blood_stage2/blood_anno2/new3\"\n",
    "file_names=os.listdir(file_folders)\n",
    "for file_name in file_names:\n",
    "    file_paths=os.path.join(file_folders,file_name)\n",
    "    files_path=os.listdir(file_paths)\n",
    "    for file_path in files_path:\n",
    "        file_path=os.path.join(file_paths,file_path)\n",
    "        nii_filename=os.path.join(file_paths,f\"{file_name}.nii\")\n",
    "        dcm_to_nii(dcm_folder, nii_filename)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hospital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
